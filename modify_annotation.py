import os
import json
import cv2
from datetime import datetime
import numpy as np
import random
import re  # å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—


# æ³¨æ„ï¼šæˆ‘ä»¬å·²ç»ç§»é™¤äº† 'from lib.utils.opts import opts'

def robust_yolo_to_coco_converter():
    """
    ä¸€ä¸ªå¥å£®çš„ã€æ”¯æŒå¤šåˆ†è¾¨ç‡å’Œæ¡ä»¶æŠ½å¸§çš„YOLOåˆ°COCOæ ¼å¼è½¬æ¢å™¨ã€‚
    - [æ ¸å¿ƒåŠŸèƒ½] è‡ªåŠ¨è¯»å–æ¯å¼ å›¾ç‰‡çš„å®é™…åˆ†è¾¨ç‡ã€‚
    - [æ ¸å¿ƒåŠŸèƒ½] ä»…å¯¹åç§°ä¸ç¬¦åˆ 'data' + æ•°å­— æ ¼å¼çš„æ–‡ä»¶å¤¹è¿›è¡ŒæŠ½å¸§ã€‚
    - èƒ½å¤Ÿè‡ªåŠ¨å‘ç°æ•°æ®æ–‡ä»¶å¤¹ã€‚
    - æ”¯æŒå¤šç±»åˆ«ã€‚
    """
    # ==================== [ æ ¸å¿ƒä¿®æ”¹ ] ====================
    # ç§»é™¤æ‰€æœ‰ opts ç›¸å…³çš„ä»£ç ï¼Œç›´æ¥åœ¨è¿™é‡ŒæŒ‡å®šè·¯å¾„
    # è¯·åœ¨è¿™é‡Œä¿®æ”¹ä¸ºæ‚¨æ•°æ®é›†çš„æ ¹ç›®å½•
    scene_dir = '/root/autodl-tmp/test_v1'
    # ==========================================================

    # 1. åŸºç¡€è·¯å¾„é…ç½®
    target_dir = scene_dir
    images_base_dir = os.path.join(scene_dir, "images")
    labels_base_dir = os.path.join(scene_dir, "labels")

    # 2. æ•°æ®é›†åˆ’åˆ†
    print("ğŸš€ æ­¥éª¤1: åŠ¨æ€å‘ç°æ–‡ä»¶å¤¹å¹¶åˆ’åˆ†æ•°æ®é›†...")
    if not os.path.exists(images_base_dir):
        print(f"âŒ é”™è¯¯: 'images' ç›®å½•ä¸å­˜åœ¨äº: {images_base_dir}")
        return False

    all_data_folders = sorted(
        [d for d in os.listdir(images_base_dir) if os.path.isdir(os.path.join(images_base_dir, d))])
    print(f"ğŸ” åœ¨ '{images_base_dir}' ä¸­å‘ç° {len(all_data_folders)} ä¸ªæ•°æ®æ–‡ä»¶å¤¹ã€‚")

    # å‡è®¾æ‰€æœ‰æ–‡ä»¶å¤¹éƒ½ç”¨äºè®­ç»ƒå’Œæµ‹è¯•
    train_data_folders = all_data_folders
    test_data_folders = all_data_folders
  
    test_data_folders = ["data_01"]
    train_data_folders = ["data_01"]
    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ: {len(train_data_folders)} è®­ç»ƒé›†, {len(test_data_folders)} æµ‹è¯•é›†")

    annotations_output_dir = os.path.join(target_dir, "annotations")
    os.makedirs(annotations_output_dir, exist_ok=True)

    def create_coco_format():
        return {
            "info": {"description": "Custom Dataset", "version": "1.0", "year": datetime.now().year,
                     "date_created": datetime.now().strftime("%Y-%m-%d")},
            "licenses": [{"id": 1, "name": "Unknown"}], "images": [], "annotations": [], "categories": []
        }

    # 3. ç±»åˆ«å®šä¹‰
    print("\nğŸ” æ­¥éª¤2: å®šä¹‰ç±»åˆ«ä¿¡æ¯...")
    yolo_class_names = ["drone", "car", "ship", "bus", "pedestrian", "cyclist"]
    categories = [{"id": i + 1, "name": name, "supercategory": "object"} for i, name in enumerate(yolo_class_names)]
    yolo_to_coco_mapping = {i: i + 1 for i in range(len(yolo_class_names))}
    print(f"ğŸ“‹ æˆåŠŸå®šä¹‰ {len(categories)} ä¸ªç±»åˆ«ã€‚")

    def process_dataset(data_folders_list, dataset_type, coco_data, frame_skip_rate_default=3):
        """
        å¤„ç†æŒ‡å®šçš„æ•°æ®é›†æ–‡ä»¶å¤¹åˆ—è¡¨ã€‚
        - åªæœ‰å½“æ–‡ä»¶å¤¹åç§°ä¸ç¬¦åˆ 'data' + æ•°å­— çš„æ ¼å¼æ—¶ï¼Œæ‰åº”ç”¨æŠ½å¸§ã€‚
        - åŠ¨æ€è¯»å–æ¯å¼ å›¾ç‰‡çš„å®é™…åˆ†è¾¨ç‡ã€‚
        """
        print(f"\n  ğŸ“‚ æ­£åœ¨å¤„ç† {dataset_type} æ•°æ®é›† ({len(data_folders_list)} ä¸ªæ–‡ä»¶å¤¹)...")
        print(f"   - é»˜è®¤æŠ½å¸§ç‡ (å½“æ–‡ä»¶å¤¹åç§°ä¸åŒ¹é…æ—¶): 1/{frame_skip_rate_default}")

        image_id_counter = 1  # æ¯ä¸ªJSONæ–‡ä»¶çš„IDéƒ½ä»1å¼€å§‹
        annotation_id_counter = 1

        for data_folder in data_folders_list:
            image_dir = os.path.join(images_base_dir, data_folder)
            label_dir = os.path.join(labels_base_dir, data_folder)

            if not os.path.exists(image_dir) or not os.path.exists(label_dir):
                print(f"   - âš ï¸  è·³è¿‡ '{data_folder}' (ç›®å½•ä¸å­˜åœ¨)")
                continue

            is_no_skip_folder = re.match(r'^data\d+$', data_folder)
            current_frame_skip_rate = 1 if is_no_skip_folder else frame_skip_rate_default

            def natural_sort_key(s):
                return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]

            image_files = sorted(
                [f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))],
                key=natural_sort_key)

            for image_index, image_file in enumerate(image_files):
                if image_index % current_frame_skip_rate != 0:
                    continue

                label_full_path = os.path.join(label_dir, os.path.splitext(image_file)[0] + '.txt')
                if not os.path.exists(label_full_path):
                    continue

                image_full_path = os.path.join(image_dir, image_file)
                try:
                    img = cv2.imread(image_full_path)
                    if img is None:
                        print(f"   - âš ï¸  è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {image_full_path}, è·³è¿‡ã€‚")
                        continue
                    image_h, image_w = img.shape[:2]
                except Exception as e:
                    print(f"   - âš ï¸  è­¦å‘Š: è¯»å–å›¾åƒå°ºå¯¸æ—¶å‡ºé”™ {image_full_path}: {e}, è·³è¿‡ã€‚")
                    continue

                relative_image_path = os.path.join('images', data_folder, image_file).replace(os.sep, '/')

                image_info = {
                    "id": image_id_counter, "width": image_w, "height": image_h,
                    "file_name": relative_image_path, "license": 1, "original_file": image_file
                }
                coco_data["images"].append(image_info)

                with open(label_full_path, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if len(parts) < 5: continue
                        yolo_class_id, x_c, y_c, w, h = map(float, parts[:5])
                        yolo_class_id = int(yolo_class_id)

                        abs_w, abs_h = w * image_w, h * image_h
                        x_min, y_min = (x_c * image_w) - (abs_w / 2), (y_c * image_h) - (abs_h / 2)

                        coco_category_id = yolo_to_coco_mapping.get(yolo_class_id)
                        if coco_category_id is None: continue

                        annotation = {
                            "id": annotation_id_counter, "image_id": image_id_counter,
                            "category_id": coco_category_id, "bbox": [x_min, y_min, abs_w, abs_h],
                            "area": abs_w * abs_h, "iscrowd": 0, "segmentation": []
                        }
                        coco_data["annotations"].append(annotation)
                        annotation_id_counter += 1
                image_id_counter += 1

    # 4. ç”Ÿæˆæ•°æ®é›†
    train_coco = create_coco_format()
    train_coco["categories"] = categories
    process_dataset(train_data_folders, "train", train_coco, frame_skip_rate_default=3)

    test_coco = create_coco_format()
    test_coco["categories"] = categories
    process_dataset(test_data_folders, "test", test_coco, frame_skip_rate_default=1)

    # 5. ä¿å­˜æ–‡ä»¶
    print("\nğŸ”§ æ­¥éª¤3: ä¿å­˜æ³¨é‡Šæ–‡ä»¶...")
    for (name, data) in [("train", train_coco), ("val", test_coco)]:  # val ä½¿ç”¨ test çš„æ•°æ®
        file_path = os.path.join(annotations_output_dir, f"instances_{name}2017.json")
        with open(file_path, 'w') as f:
            json.dump(data, f, indent=2)
        print(
            f"âœ… {name.capitalize()}é›†æ³¨é‡Šæ–‡ä»¶: {file_path} ({len(data['images'])} å›¾åƒ, {len(data['annotations'])} æ ‡æ³¨)")

    print("\nğŸ‰ æ•°æ®è½¬æ¢å®Œæˆ!")
    return True


if __name__ == "__main__":
    if robust_yolo_to_coco_converter():
        print("\nâœ… è½¬æ¢æˆåŠŸï¼ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
    else:
        print("\nâŒ è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—ã€‚")